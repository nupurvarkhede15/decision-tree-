{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* Decision tree algorithm is a supervised learning algorithm \n",
    "\n",
    "* We create a tree and divide the data \n",
    "\n",
    "* We select the feature which maximum information gain \n",
    "\n",
    "* Based on the feature we will divide the data into appropriate class. \n",
    "\n",
    "* Once a feature selected and data is divided that same feature is never used in the below tree.\n",
    "\n",
    "* Once a decision tree is created it is used for further prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day\tWeather\tTemperature\tHumidity\tWind\tPlay?\n",
    "1\tSunny\tHot\tHigh\tWeak\tNo\n",
    "2\tCloudy\tHot\tHigh\tWeak\tYes\n",
    "3\tSunny\tMild\tNormal\tStrong\tYes\n",
    "4\tCloudy\tMild\tHigh\tStrong\tYes\n",
    "5\tRainy\tMild\tHigh\tStrong\tNo\n",
    "6\tRainy\tCool\tNormal\tStrong\tNo\n",
    "7\tRainy\tMild\tHigh\tWeak\tYes\n",
    "8\tSunny\tHot\tHigh\tStrong\tNo\n",
    "9\tCloudy\tHot\tNormal\tWeak\tYes\n",
    "10\tRainy\tMild\tHigh\tStrong\tNo\n",
    "\n",
    "T = train a Decision tree algorithm\n",
    "11 cloudy   Hot     Normal       Weak      Can i go to play ?   Yes \n",
    "\n",
    "12 Rainy  MILD      NOrmal     Weak                 Yes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes to predict:  ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "print('Classes to predict: ', data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the data: 150\n"
     ]
    }
   ],
   "source": [
    "#Extracting data attributes\n",
    "X = data.data\n",
    "### Extracting target/ class labels\n",
    "y = data.target\n",
    "print('Number of examples in the data:', X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the train_test_split to create train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 47, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Decision tree classifier from the sklearn library.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 2 1 2 1 0 2 0 1 2 2 2 1 0 0 0 2 1 2 1 2 2 1 2 0 0 2 1 2 0 1 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on test data:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    " # accuracy = number of correct predictions/ total number of predictions \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy Score on test data: ', accuracy_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 2\n",
      "Predicted: 1\n",
      "Actual: 2\n",
      "Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(y_pred)):\n",
    "    if y_test[i] != y_pred[i]:\n",
    "        print(\"Actual: \" + str(y_test[i]))\n",
    "        print(\"Predicted: \" + str(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['setosa' 'versicolor' 'virginica']\n",
    "36/38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages and Disadvantages\n",
    "\n",
    "Following are the advantages of decision trees: \n",
    "- Easy to use and understand. \n",
    "- Can handle both categorical and numerical data. \n",
    "- Resistant to outliers, hence require little data preprocessing. \n",
    "- New features can be easily added. \n",
    "- Can be used to build larger classifiers by using ensemble methods.\n",
    "\n",
    "Following are the disadvantages of decision trees: \n",
    "- Prone to overfitting. \n",
    "- Require some kind of measurement as to how well they are doing. \n",
    "- Need to be careful with parameter tuning. \n",
    "- Can create biased learned trees if some classes dominate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting \n",
    "\n",
    "Overfitting means that the ML models knows too much about the training data and is not generalised. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
